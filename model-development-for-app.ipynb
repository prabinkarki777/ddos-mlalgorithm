import pandas as pd
import numpy as np
import socket
import struct
import pickle

from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
from sklearn.feature_selection import mutual_info_classif
from imblearn.over_sampling import SMOTE

# Load data
file_path = 'SDN Dataset/dataset_sdn.csv'
df = pd.read_csv(file_path)

# Check for missing values in each column
missing_values = df.isnull().sum()

# Display the number of missing values for each column
print(missing_values)

# Fill missing values without using inplace
df['rx_kbps'] = df['rx_kbps'].fillna(df['rx_kbps'].mean())
df['tot_kbps'] = df['tot_kbps'].fillna(df['tot_kbps'].mean())

# Verify that there are no missing values left
missing_values_after = df.isnull().sum()
print("Missing values in each column after imputation:\n", missing_values_after[missing_values_after > 0])

def ip_to_int(ip):
    try:
        return struct.unpack("!I", socket.inet_aton(ip))[0]
    except socket.error:
        return None  # Handle invalid IPs

# Apply the conversion function
df['src'] = df['src'].apply(ip_to_int)
df['dst'] = df['dst'].apply(ip_to_int)

# Encode Protocol
label_encoders = {}
le_protocol = LabelEncoder()
df['Protocol'] = le_protocol.fit_transform(df['Protocol'])
label_encoders['Protocol'] = le_protocol

# Initialize StandardScaler
scaler = StandardScaler()

# Select the numerical columns to scale (excluding categorical columns such as 'Label')
numerical_columns = ['pktcount', 'bytecount', 'dur', 'tot_dur', 'flows', 'packetins', 
                     'pktperflow', 'byteperflow', 'pktrate', 'Pairflow', 'port_no', 
                     'tx_bytes', 'rx_bytes', 'tx_kbps', 'rx_kbps', 'src', 'dst','dt','dur_nsec']
# Apply scaling
df[numerical_columns] = scaler.fit_transform(df[numerical_columns])


# Calculate Mutual Information (Information Gain) for the features
X = df.drop(columns=['label'])  # Features
y = df['label'] 

mutual_info = mutual_info_classif(X, y)
mi_scores = pd.Series(mutual_info, index=X.columns).sort_values(ascending=False)

# Display top 10 features based on mutual information
print("Top 10 features based on Information Gain:")
print(mi_scores.head(10))

# Select top 10 features based on Mutual Information
top_features_mi = mi_scores.head(10).index
scaler.fit(df[top_features_mi])

# Apply class balancing technique - SMOTE
smote = SMOTE(random_state=42)
X_bal, y_bal = smote.fit_resample(X[top_features_mi], y)

print(f"\nClass distribution after SMOTE:")
print(pd.Series(y_bal).value_counts())

# Split data
X_train, X_test, y_train, y_test = train_test_split(X_bal, y_bal, test_size=0.3, random_state=42)

# Train the best model
best_model = RandomForestClassifier(random_state=42)
best_model.fit(X_train, y_train)

# Evaluate the best model on the test set
y_pred = best_model.predict(X_test)
print(f"Classification report for Random Forest with Mutual Information and SMOTE:")
print(classification_report(y_test, y_pred))

# Save the model
with open('random_forest_model.pkl', 'wb') as model_file:
    pickle.dump(best_model, model_file)

# Save the scaler
with open('scaler.pkl', 'wb') as scaler_file:
    pickle.dump(scaler, scaler_file)

# Save the label encoders
with open('label_encoders.pkl', 'wb') as le_file:
    pickle.dump(label_encoders, le_file)
