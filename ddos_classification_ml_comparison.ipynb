import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix
from sklearn.model_selection import cross_val_score, KFold
from imblearn.over_sampling import RandomOverSampler, SMOTE,ADASYN
from imblearn.under_sampling import RandomUnderSampler
from sklearn.feature_selection import mutual_info_classif, chi2, f_classif, SelectKBest
import time

# Load data
file_path = 'SDN Dataset/dataset_sdn.csv'
df = pd.read_csv(file_path)

# Handle missing values
df['rx_kbps'] = df['rx_kbps'].fillna(df['rx_kbps'].mean())
df['tot_kbps'] = df['tot_kbps'].fillna(df['tot_kbps'].mean())

# Encode categorical variables
categorical_columns = ['src', 'dst', 'Protocol']
label_encoders = {}
for column in categorical_columns:
    le = LabelEncoder()
    df[column] = le.fit_transform(df[column])
    label_encoders[column] = le

# Scale numerical features
numerical_columns = ['pktcount', 'bytecount', 'dur', 'dur_nsec', 'tot_dur', 'flows', 'packetins', 
                     'pktperflow', 'byteperflow', 'pktrate', 'Pairflow', 'port_no', 'tx_bytes', 
                     'rx_bytes', 'tx_kbps', 'rx_kbps', 'tot_kbps']
scaler = StandardScaler()
df[numerical_columns] = scaler.fit_transform(df[numerical_columns])

# Define features and target
X = df.drop(columns=['label'])  # Features
y = df['label']

# Add the target variable to the DataFrame for correlation calculation
df_with_target = X.copy()
df_with_target['label'] = y

# Compute the correlation matrix
correlation_matrix = df_with_target.corr()

# Extract correlations with the target variable
correlation_with_target = correlation_matrix['label'].drop('label')

# Plot the correlation matrix
plt.figure(figsize=(20, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, 
            xticklabels=df_with_target.columns, yticklabels=df_with_target.columns)
plt.title('Correlation Matrix with Target Variable')
plt.show()

# Print correlations with the target variable
print("Correlation of features with the target variable:")
print(correlation_with_target.sort_values(ascending=False))

# Select features based on correlation with the target variable
def select_features_by_correlation(correlation_series, threshold=0.1):
    """Select features based on their correlation with the target variable."""
    selected_features = correlation_series[abs(correlation_series) > threshold].index.tolist()
    if 'label' in selected_features:
        selected_features.remove('label')
    return selected_features

# Get the selected features based on correlation threshold
selected_features_correlation = select_features_by_correlation(correlation_with_target, threshold=0.1)
print("Selected features by correlation:", selected_features_correlation)

# Calculate Information Gain for the features
mutual_info = mutual_info_classif(X, y)
mi_scores = pd.Series(mutual_info, index=X.columns).sort_values(ascending=False)

# Display top 10 features based on mutual information
print("Top 10 features based on Information Gain:")
print(mi_scores.head(10))
# Get the top 10 features for each method
top_features_mi = mi_scores.head(10).index
print("Information Gain Top Features:", list(top_features_mi))

# Apply the Chi-Square on the features
chi2_scores, p_values = chi2(X.abs(), y)  # Taking absolute to ensure no negative values
chi2_scores_series = pd.Series(chi2_scores, index=X.columns).sort_values(ascending=False)

# Display top 10 features based on Chi-square scores
print("Top 10 features based on Chi-square scores:")
print(chi2_scores_series.head(10))
top_features_chi2 = chi2_scores_series.head(10).index
print("Chi-Square Top Features:", list(top_features_chi2))

# Apply the F-test (ANOVA) on the features
f_scores, p_values = f_classif(X, y)
f_scores_series = pd.Series(f_scores, index=X.columns).sort_values(ascending=False)

# Display top 10 features based on F-test scores
print("Top 10 features based on F-test scores:")
print(f_scores_series.head(10))
top_features_f_test = f_scores_series.head(10).index
print("F-Test Top Features:", list(top_features_f_test))

# Feature selection methods
selection_methods = {
    'Information Gain': top_features_mi,
    'Chi-Square': top_features_chi2,
    'F-Test': top_features_f_test
}

# Function to apply class balancing techniques
def apply_class_balancing(X, y, technique):
    if technique == 'Random Undersampling':
        rus = RandomUnderSampler(random_state=42)
        return rus.fit_resample(X, y)
    elif technique == 'Random Oversampling':
        ros = RandomOverSampler(random_state=42)
        return ros.fit_resample(X, y)
    elif technique == 'SMOTE':
        smote = SMOTE(random_state=42)
        return smote.fit_resample(X, y)
    else:
        raise ValueError("Unknown technique")


techniques = ['Random Undersampling', 'Random Oversampling', 'SMOTE']
balanced_data = {}
X_bal, y_bal = X, y
print(f"\nClass distribution before class balancing technique:")
print(pd.Series(y_bal).value_counts())
# Apply each balancing technique
for technique in techniques:
    X_bal, y_bal = apply_class_balancing(X, y, technique)
    balanced_data[technique] = (X_bal, y_bal)
    print(f"\nClass distribution after {technique}:")
    print(pd.Series(y_bal).value_counts())

# Plotting function
def plot_class_distribution(X, y, balanced_data, filename='class_distribution.png'):
    plt.figure(figsize=(16, 12))
    
    # Plotting the original class distribution
    plt.subplot(2, 3, 1)
    pd.Series(y).value_counts().plot(kind='bar', color='salmon')
    plt.title('Class Distribution (Original)')
    plt.xlabel('Class')
    plt.ylabel('Count')
    plt.xticks(rotation=0)
    plt.ylim(0, 70000)
    
    # Plotting class distributions after each balancing technique
    techniques = list(balanced_data.keys())
    
    for i, (technique, (X_bal, y_bal)) in enumerate(balanced_data.items(), start=2):
        plt.subplot(2, 3, i)
        counts = pd.Series(y_bal).value_counts()
        counts.plot(kind='bar', color='skyblue')
        plt.title(f'Class Distribution after {technique}')
        plt.xlabel('Class')
        plt.ylabel('Count')
        plt.xticks(rotation=0)
        plt.ylim(0, 70000)  # Set y-axis limit to 70,000
    
    plt.tight_layout()
    plt.savefig(filename)
    plt.show()

# Call the plotting function with the original and balanced data
plot_class_distribution(X, y, balanced_data)

# Define a function to train and evaluate models
def train_and_evaluate(X_train, y_train, X_test, y_test):
    models = {
        'KNN': KNeighborsClassifier(),
        'Decision Tree': DecisionTreeClassifier(),
        'Random Forest': RandomForestClassifier(),
        'SVM': SVC(probability=True)
    }
    
    results = {}
    
    for name, model in models.items():
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        y_prob = model.predict_proba(X_test)[:, 1]  # Probabilities for ROC curve
        
        report = classification_report(y_test, y_pred, output_dict=True)
        print(report)
        
        results[name] = {
            'report': report,
            'accuracy': accuracy_score(y_test, y_pred),
            'precision': precision_score(y_test, y_pred),
            'recall': recall_score(y_test, y_pred),
            'f1_score': f1_score(y_test, y_pred),
            'roc_curve': roc_curve(y_test, y_prob),
            'roc_auc': auc(*roc_curve(y_test, y_prob)[:2])
        }
    
    return results

# Function to plot ROC curves
def plot_roc_curves(results, filename='roc_curves.png'):
    plt.figure(figsize=(10, 8))
    
    for model_name, metrics in results.items():
        fpr, tpr, _ = metrics['roc_curve']
        plt.plot(fpr, tpr, label=f'{model_name} (AUC = {metrics["roc_auc"]:.2f})')
    
    plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC)')
    plt.legend(loc='lower right')
    plt.savefig(filename)
    plt.show()

# Evaluate models for each feature selection method and class balancing technique
for selection_name, selected_features in selection_methods.items():
    X_selected = X[selected_features]
    
    print(f"\nFeature selection using {selection_name}")
    
    for technique in balanced_data.keys():
        X_bal, y_bal = balanced_data[technique]
        
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(X_bal, y_bal, test_size=0.3, random_state=42)
        
        # Train and evaluate models
        results = train_and_evaluate(X_train, y_train, X_test, y_test)
        
        print(f"\nResults for {technique}:")
        for model_name, metrics in results.items():
            print(f"\nModel: {model_name}")
            print(f"Accuracy: {metrics['accuracy']:.4f}")
            print(f"Precision: {metrics['precision']:.4f}")
            print(f"Recall: {metrics['recall']:.4f}")
            print(f"F1-score: {metrics['f1_score']:.4f}")
        
        # Plot ROC curves for this technique
        plot_roc_curves(results, filename=f'roc_curves_{technique.replace(" ", "_").lower()}.png')
        # Pause for 5 minutes after each run
        print("\nPausing for 5 minutes...")
        time.sleep(300)  # 300 seconds = 5 minutes
